{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'columns' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 186\u001B[0m\n\u001B[0;32m    184\u001B[0m filenames \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mNALMA_221201_235000_0600.dat.gz\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# print(filenames)\u001B[39;00m\n\u001B[1;32m--> 186\u001B[0m h5_filenames \u001B[38;5;241m=\u001B[39m \u001B[43msort_flashes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m# other keyword arguments control the grid spacing ... see the function definition\u001B[39;00m\n\u001B[0;32m    189\u001B[0m nc_names_2d, nc_names_3d \u001B[38;5;241m=\u001B[39m grid_and_plot(h5_filenames, data_out, base_date\u001B[38;5;241m=\u001B[39mdatetime(\u001B[38;5;241m2012\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m    190\u001B[0m     ctr_lat\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mctr_lat\u001B[39m\u001B[38;5;124m'\u001B[39m], ctr_lon\u001B[38;5;241m=\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mctr_lon\u001B[39m\u001B[38;5;124m'\u001B[39m], center_ID\u001B[38;5;241m=\u001B[39mcenter_ID)\n",
      "Cell \u001B[1;32mIn[1], line 67\u001B[0m, in \u001B[0;36msort_flashes\u001B[1;34m(files, base_sort_dir, params)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     66\u001B[0m     cluster \u001B[38;5;241m=\u001B[39m DBSCANFlashSorter(params)\u001B[38;5;241m.\u001B[39mcluster\n\u001B[1;32m---> 67\u001B[0m     \u001B[43msort_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# Figure out which HDF5 files were created\u001B[39;00m\n\u001B[0;32m     69\u001B[0m dataset \u001B[38;5;241m=\u001B[39m files[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\IdeaProjects\\lmatools-master\\lmatools\\flashsort\\gen_autorun.py:36\u001B[0m, in \u001B[0;36msort_files\u001B[1;34m(files, output_path, clusterer)\u001B[0m\n\u001B[0;32m     33\u001B[0m file_base_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplit(a_file)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.gz\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m outfile \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_path, file_base_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.flash\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m lmadata \u001B[38;5;241m=\u001B[39m \u001B[43mLMADataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m clusterer(lmadata)\n\u001B[0;32m     39\u001B[0m outfile_with_extension \u001B[38;5;241m=\u001B[39m outfile \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m~\\IdeaProjects\\lmatools-master\\lmatools\\io\\LMA.py:80\u001B[0m, in \u001B[0;36mLMADataset.__init__\u001B[1;34m(self, filename, data, basedate, startdate, sec_analyzed, header)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" Create a new LMA Dataset which can be used in a standardized way \u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m    by the clustering routines and written to a standardized HDF5 \u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03m    output format.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;124;03m     \u001B[39;00m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# self.load_data_from_LMA_file(filename, mask_length=file_mask_length)\u001B[39;00m\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_data_from_LMA_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m basedate \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\IdeaProjects\\lmatools-master\\lmatools\\io\\LMA.py:151\u001B[0m, in \u001B[0;36mLMADataset.load_data_from_LMA_file\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data_from_LMA_file\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[0;32m    144\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Load data from a single LMA file. Filter data using\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m        minimum number of stations and maximum chi2 values provided\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;124;03m        in the flashsort params dictionary.\u001B[39;00m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m    \u001B[39;00m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;124;03m        The data are stored in an \u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m     lma\u001B[38;5;241m=\u001B[39m\u001B[43mLMAdataFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;66;03m# lma=LMAdataFile(filename, mask_length = mask_length)\u001B[39;00m\n\u001B[0;32m    153\u001B[0m     \u001B[38;5;66;03m# make sure the number of stations are calculated from the mask\u001B[39;00m\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;66;03m# see the implementation of LMAdataFile.__get_attr__\u001B[39;00m\n\u001B[0;32m    155\u001B[0m     stns \u001B[38;5;241m=\u001B[39m lma\u001B[38;5;241m.\u001B[39mstations\n",
      "File \u001B[1;32m~\\IdeaProjects\\lmatools-master\\lmatools\\io\\LMAarrayFile.py:146\u001B[0m, in \u001B[0;36mLMAdataFile.__init__\u001B[1;34m(self, filename, iterator)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumnTypes \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    123\u001B[0m                         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m:      \u001B[38;5;28mfloat\u001B[39m,\n\u001B[0;32m    124\u001B[0m                         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlat\u001B[39m\u001B[38;5;124m'\u001B[39m:       \u001B[38;5;28mfloat\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m \n\u001B[0;32m    139\u001B[0m                     }\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumnConverters \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    142\u001B[0m                         \u001B[38;5;66;03m# 'mask':      mask_to_int,\u001B[39;00m\n\u001B[0;32m    143\u001B[0m                     }\n\u001B[1;32m--> 146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\IdeaProjects\\lmatools-master\\lmatools\\io\\LMAarrayFile.py:280\u001B[0m, in \u001B[0;36mLMAdataFile.read\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(DataFormatMatchs\u001B[38;5;241m.\u001B[39mgroup(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumnTypes[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;132;01m{0:d}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_length)\n\u001B[1;32m--> 280\u001B[0m n_columns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mcolumns\u001B[49m)\n\u001B[0;32m    281\u001B[0m field_names, types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(n_columns)), \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(n_columns))\n\u001B[0;32m    282\u001B[0m converters \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: local variable 'columns' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Example script showing how to use lmatools to sort LMA ASCII data into flashes\n",
    "and how to create gridded imagery from those flashes.\n",
    "\n",
    "The block of code at the bottom shows how to call sorting and gridding functions.\n",
    "The params dictionary controls the flash sorting parameters.\n",
    "\n",
    "USAGE:\n",
    "python flash_sort_and_grid.py /path/to/output/ lmatools/sampledata/ASCII_solutions/LYLOUT_140526_*.dat.gz\n",
    "\n",
    "Directories for the HDF5 files, grids, and plots are created within the\n",
    "directory indicated by /path/to/output/\n",
    "\"\"\"\n",
    "import sys, os, glob\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "\n",
    "from lmatools.flashsort.gen_autorun import logger_setup, sort_files\n",
    "from lmatools.flashsort.gen_sklearn import DBSCANFlashSorter\n",
    "\n",
    "from lmatools.grid.make_grids import grid_h5flashfiles, dlonlat_at_grid_center, write_cf_netcdf_latlon, write_cf_netcdf_3d_latlon\n",
    "from lmatools.vis.multiples_nc import make_plot, make_plot_3d, read_file_3d\n",
    "\n",
    "\n",
    "def tfromfile(name):\n",
    "    parts = name.split('_')\n",
    "    y, m, d = list(map(int, (parts[-3][0:2], parts[-3][2:4], parts[-3][4:6])))\n",
    "    H, M, S = list(map(int, (parts[-2][0:2], parts[-2][2:4], parts[-2][4:6])))\n",
    "    return y+2000,m,d,H,M,S\n",
    "\n",
    "def sort_flashes(files, base_sort_dir, params):\n",
    "    \"\"\" Given a list of LMA ASCII data files, created HDF5 flash-sorted data\n",
    "        files in base_sort_dir/h5_files.\n",
    "\n",
    "        params is a dictionary with the following format\n",
    "        params = {'stations':(6,99), # range of allowable numbers of contributing stations\n",
    "                  'chi2':(0,1.0),    # range of allowable chi-sq values\n",
    "                  'distance':3000.0, 'thresh_critical_time':0.15, # space and time grouping thresholds\n",
    "                  'thresh_duration':3.0, # maximum expected flash duration\n",
    "                  'mask_length':6, # length of the hexadecimal station mask column in HDF5\n",
    "                  }\n",
    "\n",
    "    \"\"\"\n",
    "    # base_sort_dir = outpath\n",
    "    logger_setup(base_sort_dir)\n",
    "    # files = lmatools.testing.test_gen_autorun_DBSCAN.get_sample_data_list()\n",
    "    h5_dir = os.path.join(base_sort_dir, 'h5_files')\n",
    "\n",
    "    y,m,d,H,M,S = tfromfile(files[0])\n",
    "    date = datetime(y,m,d, H,M,S)\n",
    "\n",
    "    # Create HDF5 flash files\n",
    "    base_out_dir = (h5_dir+\"/20%s\" %(date.strftime('%y/%b/%d')))\n",
    "    if os.path.exists(base_out_dir) == False:\n",
    "        os.makedirs(base_out_dir)\n",
    "        subprocess.call(['chmod', 'a+w', base_out_dir, h5_dir+'/20%s' %(date.strftime('%y/%b')), h5_dir+'/20%s' %(date.strftime('%y'))])\n",
    "\n",
    "    tag = ''\n",
    "    outdir = os.path.join(base_out_dir, tag)\n",
    "    info = open(os.path.join(outdir, 'input_params.py'), 'w')\n",
    "    info.write(str(params))\n",
    "    info.close()\n",
    "\n",
    "    if True:\n",
    "        cluster = DBSCANFlashSorter(params).cluster\n",
    "        sort_files(files, outdir, cluster)\n",
    "    # Figure out which HDF5 files were created\n",
    "    dataset = files[0].split('/')[1].split('_')[0]\n",
    "    filename_pattern = h5_dir + '/20%s/NALMA*.dat.flash.h5'\n",
    "    h5_filenames = glob.glob(filename_pattern % date.strftime('%y/%b/%d'))\n",
    "\n",
    "    h5_filenames.sort()\n",
    "    return h5_filenames\n",
    "\n",
    "def grid_and_plot(h5_filenames, base_sort_dir, dx=1.0e3, dy=1.0e3, dz=1.0e3, frame_interval=60.0,\n",
    "                  x_bnd=(-200.0e3, 200.0e3), y_bnd=(-200.0e3, 200.0e3), z_bnd=(0.0e3, 20.0e3),\n",
    "                  ctr_lat=33.5, ctr_lon=-101.5, center_ID='WTLMA',\n",
    "                  n_cols=2, base_date=None\n",
    "                  ):\n",
    "    \"\"\" Given a list of HDF5 filenames (sorted by time order) in h5_filenames,\n",
    "        create 2D and 3D NetCDF grids with spacing dx, dy, dz in meters,\n",
    "        frame_interval in seconds, and tuples of grid edges\n",
    "        x_bnd, y_bnd, and z_bnd in meters\n",
    "\n",
    "        The actual grids are in regular lat,lon coordinates, with spacing at the\n",
    "        grid center matched to the dx, dy values given.\n",
    "\n",
    "        n_cols controls how many columns are plotted on each page.\n",
    "\n",
    "        Grids and plots are written to base_sort_dir/grid_files/ and  base_sort_dir/plots/\n",
    "\n",
    "\t\tbase_date is used to optionally set a common reference time for each of the NetCDF grids.\n",
    "    \"\"\"\n",
    "    # not really in km, just a different name to distinguish from similar variables below.\n",
    "    dx_km=dx\n",
    "    dy_km=dy\n",
    "    x_bnd_km = x_bnd\n",
    "    y_bnd_km = y_bnd\n",
    "    z_bnd_km = z_bnd\n",
    "\n",
    "    grid_dir = os.path.join(base_sort_dir, 'grid_files')\n",
    "    plot_dir = os.path.join(base_sort_dir, 'plots')\n",
    "\n",
    "    # There are similar functions in lmatools to grid on a regular x,y grid in some map projection.\n",
    "    dx, dy, x_bnd, y_bnd = dlonlat_at_grid_center(ctr_lat, ctr_lon,\n",
    "                                dx=dx_km, dy=dy_km,\n",
    "                                x_bnd = x_bnd_km, y_bnd = y_bnd_km )\n",
    "    # print(\"dx, dy = {0}, {1} deg\".format(dx,dy))\n",
    "    # print(\"lon_range = {0} deg\".format(x_bnd))\n",
    "    # print(\"lat_range = {0} deg\".format(y_bnd))\n",
    "\n",
    "    for f in h5_filenames:\n",
    "        y,m,d,H,M,S = tfromfile(f)\n",
    "        # print y,m,d,H,M,S\n",
    "        start_time = datetime(y,m,d, H,M,S)\n",
    "        end_time   = start_time + timedelta(0,600)\n",
    "        date = start_time\n",
    "        # print start_time, end_time\n",
    "\n",
    "        outpath = grid_dir+'/20%s' %(date.strftime('%y/%b/%d'))\n",
    "        if os.path.exists(outpath) == False:\n",
    "            os.makedirs(outpath)\n",
    "            subprocess.call(['chmod', 'a+w', outpath, grid_dir+'/20%s' %(date.strftime('%y/%b')), grid_dir+'/20%s' %(date.strftime('%y'))])\n",
    "        if True:\n",
    "            grid_h5flashfiles(h5_filenames, start_time, end_time, frame_interval=frame_interval, proj_name='latlong',\n",
    "                    base_date = base_date, energy_grids=True,\n",
    "\t\t\t\t\tdx=dx, dy=dy, x_bnd=x_bnd, y_bnd=y_bnd, z_bnd=z_bnd_km,\n",
    "                    ctr_lon=ctr_lon, ctr_lat=ctr_lat, outpath = outpath,\n",
    "                    output_writer = write_cf_netcdf_latlon, output_writer_3d = write_cf_netcdf_3d_latlon,\n",
    "                    output_filename_prefix=center_ID, spatial_scale_factor=1.0\n",
    "                    )\n",
    "\n",
    "    # Create plots\n",
    "    mapping = { 'source':'lma_source',\n",
    "                'flash_extent':'flash_extent',\n",
    "                'flash_init':'flash_initiation',\n",
    "                'footprint':'flash_footprint',\n",
    "                'specific_energy':'specific_energy',\n",
    "                'flashsize_std':'flashsize_std',\n",
    "                'total_energy': 'total_energy'\n",
    "               }\n",
    "\n",
    "    nc_names = glob.glob(grid_dir+'/20%s/*.nc' %(date.strftime('%y/%b/%d')))\n",
    "    nc_names_3d = glob.glob(grid_dir+'/20%s/*_3d.nc' %(date.strftime('%y/%b/%d')))\n",
    "    nc_names_2d = list(set(nc_names) - set(nc_names_3d))\n",
    "    nc_names_2d.sort()\n",
    "    nc_names_3d.sort()\n",
    "    # outpath = plot_dir+'/20%s' %(date.strftime('%y/%b/%d'))\n",
    "    # if os.path.exists(outpath) == False:\n",
    "    #     os.makedirs(outpath)\n",
    "    #     subprocess.call(['chmod', 'a+w', outpath, plot_dir+'/20%s' %(date.strftime('%y/%b')), plot_dir+'/20%s' %(date.strftime('%y'))])\n",
    "    #\n",
    "    # for f in nc_names_2d:\n",
    "    #     gridtype = f.split('dx_')[-1].replace('.nc', '')\n",
    "    #     var = mapping[gridtype]\n",
    "    #     make_plot(f, var, n_cols=n_cols, x_name='longitude', y_name='latitude', outpath = outpath)\n",
    "\n",
    "    # for f in nc_names_3d:\n",
    "    #     gridtype = f.split('dx_')[-1].replace('.nc', '').replace('_3d', '')\n",
    "    #     var = mapping[gridtype]\n",
    "    #     # grid_range = range_mapping[gridtype]\n",
    "    #     ###Read grid files, then plot in either 2d or 3d space###\n",
    "    #     grid, grid_name, x, y, z, t, grid_t_idx, grid_x_idx, grid_z_idx = read_file_3d(f, var, x_name='longitude', y_name='latitude', z_name='altitude')\n",
    "    #     make_plot_3d(grid, grid_name, x, y, z, t,\n",
    "    #                  grid_t_idx, grid_x_idx, grid_z_idx,\n",
    "    #                  n_cols = n_cols, outpath = outpath)\n",
    "    #     #, grid_range=grid_range)\n",
    "\n",
    "    return nc_names_2d, nc_names_3d\n",
    "\n",
    "\n",
    "params = {'stations':(6,99), # range of allowable numbers of contributing stations\n",
    "              'chi2':(0,1.0),    # range of allowable chi-sq values\n",
    "              'distance':3000.0, 'thresh_critical_time':0.15, # space and time grouping thresholds\n",
    "              'thresh_duration':3.0, # maximum expected flash duration\n",
    "              'ctr_lat':34.72, 'ctr_lon':-86.64, #center lat/lon to use for flash sorting, gridding\n",
    "              # 'mask_length':6, # length of the hexadecimal station mask column in the LMA ASCII files\n",
    "              }\n",
    "center_ID='NALMA'\n",
    "data_out = r'data\\output'\n",
    "folder_path = r'data\\input'\n",
    "\n",
    "filenames = [r'data\\input\\NALMA_221201_235000_0600.dat.gz']\n",
    "# print(filenames)\n",
    "h5_filenames = sort_flashes(filenames, data_out, params)\n",
    "\n",
    "# other keyword arguments control the grid spacing ... see the function definition\n",
    "nc_names_2d, nc_names_3d = grid_and_plot(h5_filenames, data_out, base_date=datetime(2012, 1, 1),\n",
    "    ctr_lat=params['ctr_lat'], ctr_lon=params['ctr_lon'], center_ID=center_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
